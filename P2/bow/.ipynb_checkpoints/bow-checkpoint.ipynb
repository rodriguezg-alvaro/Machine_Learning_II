{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1. Bag of Words (BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from bow import BoW\n",
    "from dataset import Dataset\n",
    "from image_classifier import ImageClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocabulary(dataset: List[str], vocabulary: str = 'vocabulary', size: int = 100, feature_type: str = 'SIFT',  iterations: int = 20):\n",
    "    \"\"\"Build a vocabulary.\n",
    "\n",
    "    Args:\n",
    "        dataset: Paths to the training images.\n",
    "        vocabulary: Relative path to the file (without extension) where the vocabulary will be saved.\n",
    "        feature_type: Feature extractor { SIFT, KAZE, AKAZE }.\n",
    "        size: Number of words in the vocabulary.\n",
    "        iterations: Maximum number of K-means iterations.\n",
    "\n",
    "    \"\"\"\n",
    "    bow = BoW()\n",
    "    bow.build_vocabulary(dataset, feature_type=feature_type, vocabulary_size=size, iterations=iterations)\n",
    "    bow.save_vocabulary(vocabulary)\n",
    "\n",
    "def train_classifier(dataset: List[str], vocabulary: str = 'vocabulary', classifier: str = 'classifier', iterations: int = 100):\n",
    "    \"\"\"Train an SVM classifier.\n",
    "\n",
    "    Args:\n",
    "        dataset: Paths to the training images.\n",
    "        vocabulary: Relative path to the vocabulary file (without extension).\n",
    "        classifier: Relative path to the file (without extension) where the classifier will be saved.\n",
    "        iterations: Maximum number of SVM iterations.\n",
    "\n",
    "    \"\"\"\n",
    "    bow = BoW()\n",
    "    bow.load_vocabulary(vocabulary)\n",
    "\n",
    "    image_classifier = ImageClassifier(bow)\n",
    "    image_classifier.train(dataset, iterations=iterations)\n",
    "    image_classifier.save(classifier)\n",
    "\n",
    "def predict(dataset: List[str], dataset_name: str = \"\", vocabulary: str = 'vocabulary', classifier: str = 'classifier'):\n",
    "    \"\"\"Perform inference on a dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset: Paths to the images.\n",
    "        dataset_name: Dataset descriptive name.\n",
    "        vocabulary: Relative path to the vocabulary file (without extension).\n",
    "        classifier: Relative path to the classifier file (without extension).\n",
    "\n",
    "    \"\"\"\n",
    "    bow = BoW()\n",
    "    bow.load_vocabulary(vocabulary)\n",
    "\n",
    "    image_classifier = ImageClassifier(bow)\n",
    "    image_classifier.load(classifier)\n",
    "    image_classifier.predict(dataset, dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset.load('../dataset/training', '*.jpg')\n",
    "validation_set = Dataset.load('../dataset/validation', '*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build vocabulary and train a SVM classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_vocabulary(training_set)\n",
    "train_classifier(training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(training_set, \"Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform inference on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(validation_set, \"Validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mejora del accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "build_vocabulary(training_set, \"vocabulary\", 300)\n",
    "train_classifier(training_set)\n",
    "predict(training_set, \"Training\")\n",
    "predict(validation_set, \"Validation\")"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
